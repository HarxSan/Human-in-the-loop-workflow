ğŸ¤– Human-in-the-Loop AI Agent with Tavily, Groq Cloud, and Memory


ğŸš€ Overview


This repository contains a Human-in-the-Loop (HITL) AI Agent that intelligently combines LLM-powered automation with human intervention for enhanced decision-making.


It utilizes:


Tavily Search API for retrieving up-to-date information


Groq Cloud for lightning-fast LLM inference


Memory persistence to retain past interactions


LangGraph for workflow automation


This AI system ensures accuracy, reliability, and human oversight, making it ideal for critical applications such as research assistance, customer support, and AI-driven decision-making.



âœ¨ Features


âœ… Retrieval-Augmented Generation (RAG) using Tavily Search API


âœ… Human-in-the-Loop Decision Making for complex queries


âœ… Conversation Memory using MemorySaver for stateful interactions


âœ… Groq Cloud LLMs for cost-effective, high-speed text generation


âœ… Automated Workflow powered by LangGraph


âœ… Seamless Tool Integration for dynamic tool invocation



ğŸ—ï¸ Architecture


graph TD;

  A[User Query] -->|Passes through| B[AI Agent];
  
  
  B --> C{Does AI Know the Answer?};
  
  
  C -- Yes --> D[Generate Response Using Groq LLM];
  
  
  C -- No --> E[Invoke Tavily Search API];
  
  
  E --> F{Is More Context Needed?};
  
  
  F -- Yes --> G[Request Human Assistance];
  
  
  G --> H[Human Provides Answer];
  
  
  H --> I[Store Response in Memory];
  
  
  I --> J[Reply to User];
  
  
  F -- No --> J;
  
  
  D --> J;


This architecture ensures the AI efficiently handles queries while seeking human assistance when necessary.



âš™ï¸ Installation & Setup


1ï¸âƒ£ Clone the Repository


git clone https://github.com/yourusername/hitl-ai-agent.git


cd hitl-ai-agent


2ï¸âƒ£ Install Dependencies


pip install -r requirements.txt


3ï¸âƒ£ Set Up Environment Variables


Create a .env file and add:


TAVILY_API_KEY=your_tavily_api_key


GROQ_API_KEY=your_groq_api_key


4ï¸âƒ£ Run the AI Agent


python main.py


ğŸ› ï¸ Usage


1ï¸âƒ£ Start the Agent


Once running, the agent will listen for user queries and decide whether to:


Answer directly using Groq LLM


Search for relevant data via Tavily API


Request human intervention if required


2ï¸âƒ£ Example Query


User: What are the latest advancements in quantum computing?


Possible AI Workflow:


The AI checks memory for related queries.


If not found, it queries Tavily Search API.


If results are unclear, it asks for human input.


The final response is generated and stored.


3ï¸âƒ£ Human Intervention


When a complex query arises, the AI triggers:


AI: I need human assistance to ensure accuracy. Please provide insights.


The human expert can then review, modify, and approve the response.


ğŸ† Why This Matters


This system bridges the gap between fully autonomous AI and human expertise, making it perfect for:


ğŸ”¬ Research Assistants


ğŸ¯ Customer Support AI


ğŸ“Š Business Intelligence


ğŸ“š Educational Chatbots


ğŸŒŸ Contributing


We welcome contributions! Feel free to fork this repo, make changes, and submit a PR.


Fork the repo


Create a new branch (git checkout -b feature-branch)


Commit changes (git commit -m 'Add new feature')


Push and create a Pull Request


ğŸ“œ License


This project is licensed under the MIT License.


ğŸ’¬ Contact


For any queries, feel free to reach out:


ğŸ“§ Email: hariisankar720@gmail.comğŸ¦


Letâ€™s build smarter AI together! ğŸš€
